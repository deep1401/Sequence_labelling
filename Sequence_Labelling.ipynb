{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence Labelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii9utZ3A0Z4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzkYTRr_0D-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "26500dec-31b2-48e3-d2a1-c8b35cf2ba5d"
      },
      "source": [
        "!git clone \"https://github.com/leondz/emerging_entities_17\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'emerging_entities_17'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rremote: Total 53 (delta 0), reused 0 (delta 0), pack-reused 53\u001b[K\n",
            "Unpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vt9JhVl1V2f",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP8UHj720lzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import itertools\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.init\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls24Q6v82FBb",
        "colab_type": "text"
      },
      "source": [
        "### Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQEQ_Te-2BU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_word_tags(file, caseless=True):\n",
        "  with open(file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "  words, tags, temp_w, temp_t  = [], [], [], []\n",
        "  #r = '([^\\s+]+)\\s+(.*)'\n",
        "  #i = 0\n",
        "  for line in lines:\n",
        "    #print(i)\n",
        "    if not line.isspace():\n",
        "      #m = re.match(r, line)\n",
        "      feats = line.split('\\t')\n",
        "      assert len(feats) == 2\n",
        "      feats[1] = feats[1].strip('\\n')\n",
        "      temp_w.append(feats[0].lower() if caseless else feats[0])\n",
        "      temp_t.append(feats[1].strip())\n",
        "    elif len(temp_w) > 0:\n",
        "      assert len(temp_w) == len(temp_t)\n",
        "      words.append(temp_w)\n",
        "      tags.append(temp_t)\n",
        "      temp_w, temp_t = [], []\n",
        "    #i += 1\n",
        "  if len(temp_w) > 0:\n",
        "    assert len(temp_w) == len(temp_t)\n",
        "    words.append(temp_w)\n",
        "    tags.append(temp_t)\n",
        "  \n",
        "  assert len(words) == len(tags)\n",
        "\n",
        "  return words,tags"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qguYQITs5yEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing\n",
        "x,y = read_word_tags('/content/emerging_entities_17/wnut17train.conll')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz_P5Bg68LJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_maps(words, tags, min_word_freq=5, min_char_freq=1):\n",
        "  \"Creates word, char, tag maps\"\n",
        "  word_freq, char_freq = Counter(), Counter()\n",
        "  tag_map = set()\n",
        "  for w,t in zip(words,tags):\n",
        "    word_freq.update(w)\n",
        "    char_freq.update(list(reduce(lambda x, y: list(x)+[' ']+list(y), w)))\n",
        "    tag_map.update(t)\n",
        "\n",
        "  word_map = {k: v+1 for v, k in enumerate([w for w in word_freq.keys() if word_freq[w] > min_word_freq])}\n",
        "  char_map = {k: v+1 for v, k in enumerate([c for c in char_freq.keys() if char_freq[c] > min_char_freq])}\n",
        "  tag_map = {k: v+1 for v, k in enumerate(tag_map)}\n",
        "\n",
        "  word_map['<pad>'] = 0\n",
        "  word_map['<unk>'] = len(word_map)\n",
        "  word_map['<end>'] = len(word_map)\n",
        "  char_map['<pad>'] = 0\n",
        "  char_map['<unk>'] = len(char_map)\n",
        "  char_map['<end>'] = len(char_map)\n",
        "  tag_map['<start>'] = len(tag_map)\n",
        "  tag_map['<end>'] = len(tag_map)\n",
        "\n",
        "  return word_map, char_map, tag_map"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUwSl34ZCyC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_input_tensors(words, tags, word_map, char_map, tag_map):\n",
        "  \"Creates tensors for Pytorch dataset\"\n",
        "\n",
        "  # Encode sentences into word maps with <end>\n",
        "  wmaps = list(map(lambda s: list(map(lambda w: word_map.get(w, word_map['<unk>']), s)) + [word_map['<end>']], words))\n",
        "\n",
        "  # forward and backward character streams\n",
        "  chars_f = list(map(lambda s: list(reduce(lambda x, y: list(x) + [' '] + list(y), s)) + [' '], words))\n",
        "  chars_b = list(map(lambda s: list(reversed([' '] + list(reduce(lambda x, y: list(x) + [' '] + list(y), s)))), words))\n",
        "\n",
        "  # Encode streams into forward and backward maps with <end>\n",
        "  cmaps_f = list(map(lambda s: list(map(lambda c: char_map.get(c, char_map['<unk>']), s)) + [char_map['<end>']], chars_f))\n",
        "  cmaps_b = list(map(lambda s: list(map(lambda c: char_map.get(c, char_map['<unk>']), s)) + [char_map['<end>']], chars_b))\n",
        "\n",
        "  # Positions of spaces and <end>\n",
        "  cmarkers_f = list(map(lambda s: [ind for ind in range(len(s)) if s[ind]==char_map[' ']] + [len(s-1)], cmaps_f))\n",
        "  cmarkers_b = list(map(lambda s: list(reversed([ind for ind in range(len(s)) if s[ind]==char_map[' ']])) + [len(s-1)], cmaps_b))\n",
        "\n",
        "  # Encode tags into tag_maps with <end>\n",
        "  tmaps = list(map(lambda s: list(map(lambda t: tag_map[t], s)) + [tag_map['<end>']], tags))\n",
        "\n",
        "  # Since we use a prev_tag*cur_tag matrix for CRF scores\n",
        "  tmaps = list(map(lambda s: [tag_map['<start>'] * len(tag_map) + s[0]] + [s[i - 1] * len(tag_map) + s[i] for i in range(1, len(s))], tmaps))\n",
        "\n",
        "  # Actual tag indices to be recovered using tmaps%len(tag_map)\n",
        "\n",
        "  # Applying padding for obvious reasons\n",
        "  word_pad_len = max(list(map(lambda s: len(s), wmaps)))\n",
        "  char_pad_len = max(list(map(lambda s: len(s), cmaps_f)))  #Since sentence length is constant in forward and backward\n",
        "\n",
        "  # Sanity Check\n",
        "  assert word_pad_len == max(list(map(lambda s: len(s), tmaps)))\n",
        "\n",
        "  padded_wmaps, padded_cmaps_f, padded_cmaps_b, padded_cmarkers_f, padded_cmarkers_b, padded_tmaps, wmap_lengths, cmap_lengths = [], [], [], [], [], [], [], []\n",
        "\n",
        "  for w, cf, cb, cmf, cmb, t in zip(wmaps, cmaps_f, cmaps_b, cmarkers_f, cmarkers_b, tmaps):\n",
        "    # Sanity  checks\n",
        "    assert len(w) == len(cmf) == len(cmb) == len(t)\n",
        "    assert len(cmaps_f) == len(cmaps_b)\n",
        "    \n",
        "    padded_wmaps.append(w + [word_map['<pad>']] * (word_pad_len - len(w)))\n",
        "    padded_cmaps_f.append(cf + [char_map['<pad>']] * (char_pad_len - len(cf)))\n",
        "    padded_cmaps_b.append(cb + [char_map['<pad>']] * (char_pad_len - len(cb)))\n",
        "\n",
        "    # Padding with index 0 for markers\n",
        "    padded_cmarkers_f.append(cmf + [0] * (word_pad_len - len(w)))\n",
        "    padded_cmarkers_b.append(cmb + [0] * (word_pad_len - len(w)))\n",
        "\n",
        "    padded_tmaps.append(t + [tag_map['<pad>']] * (word_pad_len - len(t)))\n",
        "\n",
        "    wmap_lengths.append(len(w))\n",
        "    cmap_lengths.append(len(cf))\n",
        "\n",
        "    # Sanity check\n",
        "    assert len(padded_wmaps[-1]) == len(padded_tmaps[-1]) == len(padded_cmarkers_f[-1]) == len(padded_cmarkers_b[-1]) == word_pad_len\n",
        "    assert len(padded_cmaps_f[-1]) == len(padded_cmaps_b[-1]) == char_pad_len\n",
        "\n",
        "  padded_wmaps = torch.LongTensor(padded_wmaps)\n",
        "  padded_cmaps_f = torch.LongTensor(padded_cmaps_f)\n",
        "  padded_cmaps_b = torch.LongTensor(padded_cmaps_b)\n",
        "  padded_cmarkers_f = torch.LongTensor(padded_cmarkers_f)\n",
        "  padded_cmarkers_b = torch.LongTensor(padded_cmarkers_b)\n",
        "  padded_tmaps = torch.LongTensor(padded_tmaps)\n",
        "  wmap_lengths = torch.LongTensor(wmap_lengths)\n",
        "  cmap_lengths = torch.LongTensor(cmap_lengths)\n",
        "\n",
        "  return padded_wmaps, padded_cmaps_f, padded_cmaps_b, padded_cmarkers_f, padded_cmarkers_b, padded_tmaps, wmap_lengths, cmap_lengths"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr8TbPniJD1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_embedding(input_embedding):\n",
        "  \"Initializing embedding tensor using uniformly distributed values\"\n",
        "  bias = np.sqrt(3.0/input_embedding.size(1))\n",
        "  nn.init.uniform_(input_embedding, -bias, bias)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTF7Bb0w73Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embeddings(emb_file, word_map, expand_vocab=True):\n",
        "  \"Load Pre Trained embeddings\"\n",
        "  with open(emb_file, 'r') as f:\n",
        "    emb_len = len(f.readline().split(' ')) - 1\n",
        "  \n",
        "  print(f\"Embedding length is {emb_len}\")\n",
        "\n",
        "  ic_embs = torch.FloatTensor(len(word_map), emb_len)\n",
        "  init_embedding(ic_embs)\n",
        "\n",
        "  if expand_vocab:\n",
        "    print(\"You have selected to include out of corpus embeddings\")\n",
        "    ooc_words, ooc_embeds = [], []\n",
        "\n",
        "  else:\n",
        "    print(\"Not including out of corpus word embeddings\")\n",
        "\n",
        "  print(\"\\nLoading Embeddings :)\")\n",
        "  \n",
        "  for line in open(emb_file,'r'):\n",
        "    line = line.split(' ')\n",
        "    emb_word = line[0]\n",
        "\n",
        "    embedding = list(map(lambda t: float(t), filter(lambda n: n and not n.isspace(), line[1:])))\n",
        "\n",
        "    if not expand_vocab and emb_word not in word_map:\n",
        "      continue\n",
        "    \n",
        "    if emb_word in word_map:\n",
        "      ic_embs[word_map[emb_word]] = torch.FloatTensor(embedding)\n",
        "\n",
        "    elif expand_vocab:\n",
        "      ooc_words.append(emb_word)\n",
        "      ooc_embeds.append(embedding)\n",
        "\n",
        "  lm_vocab_size = len(word_map)\n",
        "\n",
        "  if expand_vocab:\n",
        "    print(\"Updating Word Map\")\n",
        "    for word in ooc_words:\n",
        "      word_map[word] = len(word_map)\n",
        "    ooc_embs = torch.FloatTensor(np.asarray(ooc_embs))\n",
        "    embeddings = torch.cat([ic_embs,ooc_embs], 0)\n",
        "\n",
        "  else:\n",
        "    embeddings = ic_embs\n",
        "\n",
        "  assert embeddings.size(0) == len(word_map)\n",
        "\n",
        "  print(f'Process completed successfully.\\nEmbedding vocabulary: {len(word_map)}\\n Language Model Vocabulary: {lm_vocab_size}')\n",
        "\n",
        "  return embeddings, word_map, lm_vocab_size"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJOkpj9c_Kk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clip_gradient(optimizer, grad_clip):\n",
        "  \"Clip gradients during backpropogation to prevent gradient explosion\"\n",
        "  for group in optimizer.param_groups:\n",
        "    for param in group['params']:\n",
        "      if param.grad is not None:\n",
        "        param.grad.data.clamp_(-grad_clip, grad_clip)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0sYUEr2_r37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(epoch, model, optimizer, val_f1, word_map, char_map, tag_map, lm_vocab_size, is_best):\n",
        "  \"Save model checkpoint\"\n",
        "\n",
        "  state = {'epoch':epoch,\n",
        "           'f1' : val_f1,\n",
        "           'model': model,\n",
        "           'optimizer':optimizer,\n",
        "           'word_map':word_map,\n",
        "           'tag_map': tag_map,\n",
        "           'char_map': char_map,\n",
        "           'lm_vocab_size':lm_vocab_size}\n",
        "\n",
        "  filename = 'checkpoint_lm_lstm_crf.pth.tar'\n",
        "  torch.save(state, filename)\n",
        "  if is_best:\n",
        "    torch.save(state,'BEST_'+filename)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ6fftbJAqXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "  \"Keeps track of most recent average,sum and count of a metric\"\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "  \n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val*n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bsHJsmXBcgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust_learning_rate(optimizer, new_lr):\n",
        "  \"Shrinks learning rate by a given factor\"\n",
        "  print(\"Decaying Learning rate\")\n",
        "  \n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = new_lr\n",
        "\n",
        "  print(f\"The new learning rate is now {optimizer.param_groups[0]['lr']}\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhOE3N54CBgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_sum_exp(tensor, dim):\n",
        "  \"Calculates the log-sum-exponent in a stable way\"\n",
        "  m, _ = torch.max(tensor, dim)\n",
        "  m_expanded = m.unsqueeze(dim).expand_as(tensor)\n",
        "  return m + torch.log(torch.sum(torch.exp(tensor - m_expanded), dim))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be44ntNTCl7A",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frLlWdoMCgYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WCDataset(Dataset):\n",
        "  \"Dataset to be used by dataloader\"\n",
        "  def __init__(self, wmaps, cmaps_f, cmaps_b, cmarkers_f, cmarkers_b, tmaps, wmap_lengths, cmap_lengths):\n",
        "    self.wmaps = wmaps\n",
        "    self.cmaps_f = cmaps_f\n",
        "    self.cmaps_b = cmaps_b\n",
        "    self.cmarkers_f = cmarkers_f\n",
        "    self.cmarkers_b = cmarkers_b\n",
        "    self.tmaps = tmaps\n",
        "    self.wmap_lengths = wmap_lengths\n",
        "    self.cmap_lenghts = cmap_lengths\n",
        "    self.data_size = self.wmaps.size(0)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.wmaps[i], self.cmaps_f[i], self.cmaps_b[i], self.cmarkers_f[i], self.cmarkers_b[i], self.tmaps[i], self.wmap_lengths[i], self.cmap_lengths[i]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data_size"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BivJz656G0ZY",
        "colab_type": "text"
      },
      "source": [
        "### Testing Dynamic RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5petMyJD8Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensor with variable lengths and pads(25)\n",
        "seqs = torch.LongTensor([[0,1,2,3,25,25,25],\n",
        "                         [4,5,25,25,25,25,25],\n",
        "                         [6,7,8,9,10,11,25]])"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5bLNVX4HRIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Storing original lengths\n",
        "seq_lens = torch.LongTensor([4,2,6])"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRHtFPD7HSRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort by decreasing lengths\n",
        "seq_lens, sort_ind = seq_lens.sort(dim = 0, descending=True)\n",
        "seqs = seqs[sort_ind]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kUVLEVWHjxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeds = nn.Embedding(26,10, padding_idx=25)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUNHTUwpHlmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm = nn.LSTM(10, 50, bidirectional=False, batch_first=True)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtC7YyWhID-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Without dynamic batching\n",
        "embeddings = embeds(seqs)\n",
        "out_static, _ = lstm(embeddings)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quKBSDxNIFIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert out_static.size(1) == embeddings.size(1)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXLANLkFIprY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f5cf7311-e214-468a-a0a7-70aa273f0b6f"
      },
      "source": [
        "out_static[1,-1]"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0119,  0.0027,  0.0061,  0.0786,  0.1278, -0.0046,  0.0359,  0.0562,\n",
              "         0.0026,  0.0846, -0.0501, -0.0274, -0.0561, -0.0109, -0.0523, -0.0353,\n",
              "         0.0968, -0.0874, -0.0330,  0.1150,  0.0598, -0.0217, -0.0538, -0.0602,\n",
              "        -0.1130,  0.0985,  0.0642, -0.0596, -0.0416, -0.0739, -0.0075, -0.0026,\n",
              "        -0.1013, -0.0197, -0.0187,  0.0071,  0.0074, -0.0375,  0.1002, -0.0072,\n",
              "        -0.0076, -0.0448,  0.0792,  0.0015, -0.0398,  0.0789,  0.0195, -0.0549,\n",
              "        -0.0794, -0.0272], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CVz6MtxIxGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With Dynamic Batching\n",
        "packed_seqs = pack_padded_sequence(embeddings, seq_lens.tolist(), batch_first=True)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F05XdlUdJKxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_dynamic, _ = lstm(packed_seqs)\n",
        "out_dynamic, lens = pad_packed_sequence(out_dynamic, batch_first=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfimlkByJcx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert out_dynamic.size(1) != embeddings.size(1)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwQYxKfuJhP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d14eae6d-34bc-4a43-8f1d-c7069154f72f"
      },
      "source": [
        "# Padded length is the length of the longest sequence\n",
        "out_dynamic.shape"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 6, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU05S8xUJoa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "684618cb-8c4d-429d-f1ab-55db689b4cac"
      },
      "source": [
        "out_dynamic[1,-1]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZveaXKxMJzWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "48728fa9-d622-40a1-a391-3b6ff8617d1f"
      },
      "source": [
        "seqs"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6,  7,  8,  9, 10, 11, 25],\n",
              "        [ 0,  1,  2,  3, 25, 25, 25],\n",
              "        [ 4,  5, 25, 25, 25, 25, 25]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZIFHbYPJ7Wv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "de85537c-edc4-4966-d35d-11d6bad69483"
      },
      "source": [
        "packed_seqs = pack_padded_sequence(seqs, seq_lens, batch_first=True)\n",
        "packed_seqs[0]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6,  0,  4,  7,  1,  5,  8,  2,  9,  3, 10, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPFmkzcKKC6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ee5467ca-becd-472f-9ec3-193d78097c82"
      },
      "source": [
        "# Look at the batch size in seqs at each time step, this is equal to that\n",
        "packed_seqs[1]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 3, 2, 2, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iwscu8yKMhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}