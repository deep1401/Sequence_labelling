{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sequence Labelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii9utZ3A0Z4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzkYTRr_0D-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "26500dec-31b2-48e3-d2a1-c8b35cf2ba5d"
      },
      "source": [
        "!git clone \"https://github.com/leondz/emerging_entities_17\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'emerging_entities_17'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "Unpacking objects:   1% (1/53)   \rUnpacking objects:   3% (2/53)   \rUnpacking objects:   5% (3/53)   \rUnpacking objects:   7% (4/53)   \rUnpacking objects:   9% (5/53)   \rUnpacking objects:  11% (6/53)   \rUnpacking objects:  13% (7/53)   \rUnpacking objects:  15% (8/53)   \rUnpacking objects:  16% (9/53)   \rUnpacking objects:  18% (10/53)   \rUnpacking objects:  20% (11/53)   \rUnpacking objects:  22% (12/53)   \rUnpacking objects:  24% (13/53)   \rUnpacking objects:  26% (14/53)   \rUnpacking objects:  28% (15/53)   \rUnpacking objects:  30% (16/53)   \rUnpacking objects:  32% (17/53)   \rUnpacking objects:  33% (18/53)   \rUnpacking objects:  35% (19/53)   \rUnpacking objects:  37% (20/53)   \rUnpacking objects:  39% (21/53)   \rUnpacking objects:  41% (22/53)   \rUnpacking objects:  43% (23/53)   \rUnpacking objects:  45% (24/53)   \rUnpacking objects:  47% (25/53)   \rUnpacking objects:  49% (26/53)   \rUnpacking objects:  50% (27/53)   \rUnpacking objects:  52% (28/53)   \rUnpacking objects:  54% (29/53)   \rUnpacking objects:  56% (30/53)   \rUnpacking objects:  58% (31/53)   \rUnpacking objects:  60% (32/53)   \rUnpacking objects:  62% (33/53)   \rUnpacking objects:  64% (34/53)   \rUnpacking objects:  66% (35/53)   \rUnpacking objects:  67% (36/53)   \rUnpacking objects:  69% (37/53)   \rUnpacking objects:  71% (38/53)   \rUnpacking objects:  73% (39/53)   \rUnpacking objects:  75% (40/53)   \rUnpacking objects:  77% (41/53)   \rUnpacking objects:  79% (42/53)   \rUnpacking objects:  81% (43/53)   \rUnpacking objects:  83% (44/53)   \rUnpacking objects:  84% (45/53)   \rremote: Total 53 (delta 0), reused 0 (delta 0), pack-reused 53\u001b[K\n",
            "Unpacking objects:  86% (46/53)   \rUnpacking objects:  88% (47/53)   \rUnpacking objects:  90% (48/53)   \rUnpacking objects:  92% (49/53)   \rUnpacking objects:  94% (50/53)   \rUnpacking objects:  96% (51/53)   \rUnpacking objects:  98% (52/53)   \rUnpacking objects: 100% (53/53)   \rUnpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vt9JhVl1V2f",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP8UHj720lzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import itertools\n",
        "from functools import reduce\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn as nn\n",
        "import torch.nn.init\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ls24Q6v82FBb",
        "colab_type": "text"
      },
      "source": [
        "### Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQEQ_Te-2BU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_word_tags(file, caseless=True):\n",
        "  with open(file, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "  words, tags, temp_w, temp_t  = [], [], [], []\n",
        "  #r = '([^\\s+]+)\\s+(.*)'\n",
        "  #i = 0\n",
        "  for line in lines:\n",
        "    #print(i)\n",
        "    if not line.isspace():\n",
        "      #m = re.match(r, line)\n",
        "      feats = line.split('\\t')\n",
        "      assert len(feats) == 2\n",
        "      feats[1] = feats[1].strip('\\n')\n",
        "      temp_w.append(feats[0].lower() if caseless else feats[0])\n",
        "      temp_t.append(feats[1].strip())\n",
        "    elif len(temp_w) > 0:\n",
        "      assert len(temp_w) == len(temp_t)\n",
        "      words.append(temp_w)\n",
        "      tags.append(temp_t)\n",
        "      temp_w, temp_t = [], []\n",
        "    #i += 1\n",
        "  if len(temp_w) > 0:\n",
        "    assert len(temp_w) == len(temp_t)\n",
        "    words.append(temp_w)\n",
        "    tags.append(temp_t)\n",
        "  \n",
        "  assert len(words) == len(tags)\n",
        "\n",
        "  return words,tags"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qguYQITs5yEv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing\n",
        "x,y = read_word_tags('/content/emerging_entities_17/wnut17train.conll')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz_P5Bg68LJ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_maps(words, tags, min_word_freq=5, min_char_freq=1):\n",
        "  \"Creates word, char, tag maps\"\n",
        "  word_freq, char_freq = Counter(), Counter()\n",
        "  tag_map = set()\n",
        "  for w,t in zip(words,tags):\n",
        "    word_freq.update(w)\n",
        "    char_freq.update(list(reduce(lambda x, y: list(x)+[' ']+list(y), w)))\n",
        "    tag_map.update(t)\n",
        "\n",
        "  word_map = {k: v+1 for v, k in enumerate([w for w in word_freq.keys() if word_freq[w] > min_word_freq])}\n",
        "  char_map = {k: v+1 for v, k in enumerate([c for c in char_freq.keys() if char_freq[c] > min_char_freq])}\n",
        "  tag_map = {k: v+1 for v, k in enumerate(tag_map)}\n",
        "\n",
        "  word_map['<pad>'] = 0\n",
        "  word_map['<unk>'] = len(word_map)\n",
        "  word_map['<end>'] = len(word_map)\n",
        "  char_map['<pad>'] = 0\n",
        "  char_map['<unk>'] = len(char_map)\n",
        "  char_map['<end>'] = len(char_map)\n",
        "  tag_map['<start>'] = len(tag_map)\n",
        "  tag_map['<end>'] = len(tag_map)\n",
        "\n",
        "  return word_map, char_map, tag_map"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUwSl34ZCyC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_input_tensors(words, tags, word_map, char_map, tag_map):\n",
        "  \"Creates tensors for Pytorch dataset\"\n",
        "\n",
        "  # Encode sentences into word maps with <end>\n",
        "  wmaps = list(map(lambda s: list(map(lambda w: word_map.get(w, word_map['<unk>']), s)) + [word_map['<end>']], words))\n",
        "\n",
        "  # forward and backward character streams\n",
        "  chars_f = list(map(lambda s: list(reduce(lambda x, y: list(x) + [' '] + list(y), s)) + [' '], words))\n",
        "  chars_b = list(map(lambda s: list(reversed([' '] + list(reduce(lambda x, y: list(x) + [' '] + list(y), s)))), words))\n",
        "\n",
        "  # Encode streams into forward and backward maps with <end>\n",
        "  cmaps_f = list(map(lambda s: list(map(lambda c: char_map.get(c, char_map['<unk>']), s)) + [char_map['<end>']], chars_f))\n",
        "  cmaps_b = list(map(lambda s: list(map(lambda c: char_map.get(c, char_map['<unk>']), s)) + [char_map['<end>']], chars_b))\n",
        "\n",
        "  # Positions of spaces and <end>\n",
        "  cmarkers_f = list(map(lambda s: [ind for ind in range(len(s)) if s[ind]==char_map[' ']] + [len(s-1)], cmaps_f))\n",
        "  cmarkers_b = list(map(lambda s: list(reversed([ind for ind in range(len(s)) if s[ind]==char_map[' ']])) + [len(s-1)], cmaps_b))\n",
        "\n",
        "  # Encode tags into tag_maps with <end>\n",
        "  tmaps = list(map(lambda s: list(map(lambda t: tag_map[t], s)) + [tag_map['<end>']], tags))\n",
        "\n",
        "  # Since we use a prev_tag*cur_tag matrix for CRF scores\n",
        "  tmaps = list(map(lambda s: [tag_map['<start>'] * len(tag_map) + s[0]] + [s[i - 1] * len(tag_map) + s[i] for i in range(1, len(s))], tmaps))\n",
        "\n",
        "  # Actual tag indices to be recovered using tmaps%len(tag_map)\n",
        "\n",
        "  # Applying padding for obvious reasons\n",
        "  word_pad_len = max(list(map(lambda s: len(s), wmaps)))\n",
        "  char_pad_len = max(list(map(lambda s: len(s), cmaps_f)))  #Since sentence length is constant in forward and backward\n",
        "\n",
        "  # Sanity Check\n",
        "  assert word_pad_len == max(list(map(lambda s: len(s), tmaps)))\n",
        "\n",
        "  padded_wmaps, padded_cmaps_f, padded_cmaps_b, padded_cmarkers_f, padded_cmarkers_b, padded_tmaps, wmap_lengths, cmap_lengths = [], [], [], [], [], [], [], []\n",
        "\n",
        "  for w, cf, cb, cmf, cmb, t in zip(wmaps, cmaps_f, cmaps_b, cmarkers_f, cmarkers_b, tmaps):\n",
        "    # Sanity  checks\n",
        "    assert len(w) == len(cmf) == len(cmb) == len(t)\n",
        "    assert len(cmaps_f) == len(cmaps_b)\n",
        "    \n",
        "    padded_wmaps.append(w + [word_map['<pad>']] * (word_pad_len - len(w)))\n",
        "    padded_cmaps_f.append(cf + [char_map['<pad>']] * (char_pad_len - len(cf)))\n",
        "    padded_cmaps_b.append(cb + [char_map['<pad>']] * (char_pad_len - len(cb)))\n",
        "\n",
        "    # Padding with index 0 for markers\n",
        "    padded_cmarkers_f.append(cmf + [0] * (word_pad_len - len(w)))\n",
        "    padded_cmarkers_b.append(cmb + [0] * (word_pad_len - len(w)))\n",
        "\n",
        "    padded_tmaps.append(t + [tag_map['<pad>']] * (word_pad_len - len(t)))\n",
        "\n",
        "    wmap_lengths.append(len(w))\n",
        "    cmap_lengths.append(len(cf))\n",
        "\n",
        "    # Sanity check\n",
        "    assert len(padded_wmaps[-1]) == len(padded_tmaps[-1]) == len(padded_cmarkers_f[-1]) == len(padded_cmarkers_b[-1]) == word_pad_len\n",
        "    assert len(padded_cmaps_f[-1]) == len(padded_cmaps_b[-1]) == char_pad_len\n",
        "\n",
        "  padded_wmaps = torch.LongTensor(padded_wmaps)\n",
        "  padded_cmaps_f = torch.LongTensor(padded_cmaps_f)\n",
        "  padded_cmaps_b = torch.LongTensor(padded_cmaps_b)\n",
        "  padded_cmarkers_f = torch.LongTensor(padded_cmarkers_f)\n",
        "  padded_cmarkers_b = torch.LongTensor(padded_cmarkers_b)\n",
        "  padded_tmaps = torch.LongTensor(padded_tmaps)\n",
        "  wmap_lengths = torch.LongTensor(wmap_lengths)\n",
        "  cmap_lengths = torch.LongTensor(cmap_lengths)\n",
        "\n",
        "  return padded_wmaps, padded_cmaps_f, padded_cmaps_b, padded_cmarkers_f, padded_cmarkers_b, padded_tmaps, wmap_lengths, cmap_lengths"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr8TbPniJD1F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_embedding(input_embedding):\n",
        "  \"Initializing embedding tensor using uniformly distributed values\"\n",
        "  bias = np.sqrt(3.0/input_embedding.size(1))\n",
        "  nn.init.uniform_(input_embedding, -bias, bias)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTF7Bb0w73Cs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_embeddings(emb_file, word_map, expand_vocab=True):\n",
        "  \"Load Pre Trained embeddings\"\n",
        "  with open(emb_file, 'r') as f:\n",
        "    emb_len = len(f.readline().split(' ')) - 1\n",
        "  \n",
        "  print(f\"Embedding length is {emb_len}\")\n",
        "\n",
        "  ic_embs = torch.FloatTensor(len(word_map), emb_len)\n",
        "  init_embedding(ic_embs)\n",
        "\n",
        "  if expand_vocab:\n",
        "    print(\"You have selected to include out of corpus embeddings\")\n",
        "    ooc_words, ooc_embeds = [], []\n",
        "\n",
        "  else:\n",
        "    print(\"Not including out of corpus word embeddings\")\n",
        "\n",
        "  print(\"\\nLoading Embeddings :)\")\n",
        "  \n",
        "  for line in open(emb_file,'r'):\n",
        "    line = line.split(' ')\n",
        "    emb_word = line[0]\n",
        "\n",
        "    embedding = list(map(lambda t: float(t), filter(lambda n: n and not n.isspace(), line[1:])))\n",
        "\n",
        "    if not expand_vocab and emb_word not in word_map:\n",
        "      continue\n",
        "    \n",
        "    if emb_word in word_map:\n",
        "      ic_embs[word_map[emb_word]] = torch.FloatTensor(embedding)\n",
        "\n",
        "    elif expand_vocab:\n",
        "      ooc_words.append(emb_word)\n",
        "      ooc_embeds.append(embedding)\n",
        "\n",
        "  lm_vocab_size = len(word_map)\n",
        "\n",
        "  if expand_vocab:\n",
        "    print(\"Updating Word Map\")\n",
        "    for word in ooc_words:\n",
        "      word_map[word] = len(word_map)\n",
        "    ooc_embs = torch.FloatTensor(np.asarray(ooc_embs))\n",
        "    embeddings = torch.cat([ic_embs,ooc_embs], 0)\n",
        "\n",
        "  else:\n",
        "    embeddings = ic_embs\n",
        "\n",
        "  assert embeddings.size(0) == len(word_map)\n",
        "\n",
        "  print(f'Process completed successfully.\\nEmbedding vocabulary: {len(word_map)}\\n Language Model Vocabulary: {lm_vocab_size}')\n",
        "\n",
        "  return embeddings, word_map, lm_vocab_size"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJOkpj9c_Kk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clip_gradient(optimizer, grad_clip):\n",
        "  \"Clip gradients during backpropogation to prevent gradient explosion\"\n",
        "  for group in optimizer.param_groups:\n",
        "    for param in group['params']:\n",
        "      if param.grad is not None:\n",
        "        param.grad.data.clamp_(-grad_clip, grad_clip)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0sYUEr2_r37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_checkpoint(epoch, model, optimizer, val_f1, word_map, char_map, tag_map, lm_vocab_size, is_best):\n",
        "  \"Save model checkpoint\"\n",
        "\n",
        "  state = {'epoch':epoch,\n",
        "           'f1' : val_f1,\n",
        "           'model': model,\n",
        "           'optimizer':optimizer,\n",
        "           'word_map':word_map,\n",
        "           'tag_map': tag_map,\n",
        "           'char_map': char_map,\n",
        "           'lm_vocab_size':lm_vocab_size}\n",
        "\n",
        "  filename = 'checkpoint_lm_lstm_crf.pth.tar'\n",
        "  torch.save(state, filename)\n",
        "  if is_best:\n",
        "    torch.save(state,'BEST_'+filename)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ6fftbJAqXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AverageMeter(object):\n",
        "  \"Keeps track of most recent average,sum and count of a metric\"\n",
        "  def __init__(self):\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.val = 0\n",
        "    self.avg = 0\n",
        "    self.sum = 0\n",
        "    self.count = 0\n",
        "  \n",
        "  def update(self, val, n=1):\n",
        "    self.val = val\n",
        "    self.sum += val*n\n",
        "    self.count += n\n",
        "    self.avg = self.sum / self.count"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bsHJsmXBcgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def adjust_learning_rate(optimizer, new_lr):\n",
        "  \"Shrinks learning rate by a given factor\"\n",
        "  print(\"Decaying Learning rate\")\n",
        "  \n",
        "  for param_group in optimizer.param_groups:\n",
        "    param_group['lr'] = new_lr\n",
        "\n",
        "  print(f\"The new learning rate is now {optimizer.param_groups[0]['lr']}\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhOE3N54CBgB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_sum_exp(tensor, dim):\n",
        "  \"Calculates the log-sum-exponent in a stable way\"\n",
        "  m, _ = torch.max(tensor, dim)\n",
        "  m_expanded = m.unsqueeze(dim).expand_as(tensor)\n",
        "  return m + torch.log(torch.sum(torch.exp(tensor - m_expanded), dim))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be44ntNTCl7A",
        "colab_type": "text"
      },
      "source": [
        "### Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frLlWdoMCgYV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WCDataset(Dataset):\n",
        "  \"Dataset to be used by dataloader\"\n",
        "  def __init__(self, wmaps, cmaps_f, cmaps_b, cmarkers_f, cmarkers_b, tmaps, wmap_lengths, cmap_lengths):\n",
        "    self.wmaps = wmaps\n",
        "    self.cmaps_f = cmaps_f\n",
        "    self.cmaps_b = cmaps_b\n",
        "    self.cmarkers_f = cmarkers_f\n",
        "    self.cmarkers_b = cmarkers_b\n",
        "    self.tmaps = tmaps\n",
        "    self.wmap_lengths = wmap_lengths\n",
        "    self.cmap_lenghts = cmap_lengths\n",
        "    self.data_size = self.wmaps.size(0)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "    return self.wmaps[i], self.cmaps_f[i], self.cmaps_b[i], self.cmarkers_f[i], self.cmarkers_b[i], self.tmaps[i], self.wmap_lengths[i], self.cmap_lengths[i]\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.data_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BivJz656G0ZY",
        "colab_type": "text"
      },
      "source": [
        "### Testing Dynamic RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J5petMyJD8Xc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tensor with variable lengths and pads(25)\n",
        "seqs = torch.LongTensor([[0,1,2,3,25,25,25],\n",
        "                         [4,5,25,25,25,25,25],\n",
        "                         [6,7,8,9,10,11,25]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5bLNVX4HRIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Storing original lengths\n",
        "seq_lens = torch.LongTensor([4,2,6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRHtFPD7HSRj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Sort by decreasing lengths\n",
        "seq_lens, sort_ind = seq_lens.sort(dim = 0, descending=True)\n",
        "seqs = seqs[sort_ind]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kUVLEVWHjxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeds = nn.Embedding(26,10, padding_idx=25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUNHTUwpHlmQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lstm = nn.LSTM(10, 50, bidirectional=False, batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtC7YyWhID-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Without dynamic batching\n",
        "embeddings = embeds(seqs)\n",
        "out_static, _ = lstm(embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quKBSDxNIFIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert out_static.size(1) == embeddings.size(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXLANLkFIprY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "f5cf7311-e214-468a-a0a7-70aa273f0b6f"
      },
      "source": [
        "out_static[1,-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0119,  0.0027,  0.0061,  0.0786,  0.1278, -0.0046,  0.0359,  0.0562,\n",
              "         0.0026,  0.0846, -0.0501, -0.0274, -0.0561, -0.0109, -0.0523, -0.0353,\n",
              "         0.0968, -0.0874, -0.0330,  0.1150,  0.0598, -0.0217, -0.0538, -0.0602,\n",
              "        -0.1130,  0.0985,  0.0642, -0.0596, -0.0416, -0.0739, -0.0075, -0.0026,\n",
              "        -0.1013, -0.0197, -0.0187,  0.0071,  0.0074, -0.0375,  0.1002, -0.0072,\n",
              "        -0.0076, -0.0448,  0.0792,  0.0015, -0.0398,  0.0789,  0.0195, -0.0549,\n",
              "        -0.0794, -0.0272], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CVz6MtxIxGv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# With Dynamic Batching\n",
        "packed_seqs = pack_padded_sequence(embeddings, seq_lens.tolist(), batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F05XdlUdJKxb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_dynamic, _ = lstm(packed_seqs)\n",
        "out_dynamic, lens = pad_packed_sequence(out_dynamic, batch_first=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfimlkByJcx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert out_dynamic.size(1) != embeddings.size(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwQYxKfuJhP4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d14eae6d-34bc-4a43-8f1d-c7069154f72f"
      },
      "source": [
        "# Padded length is the length of the longest sequence\n",
        "out_dynamic.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 6, 50])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YU05S8xUJoa8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "684618cb-8c4d-429d-f1ab-55db689b4cac"
      },
      "source": [
        "out_dynamic[1,-1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZveaXKxMJzWR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "48728fa9-d622-40a1-a391-3b6ff8617d1f"
      },
      "source": [
        "seqs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 6,  7,  8,  9, 10, 11, 25],\n",
              "        [ 0,  1,  2,  3, 25, 25, 25],\n",
              "        [ 4,  5, 25, 25, 25, 25, 25]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZIFHbYPJ7Wv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "de85537c-edc4-4966-d35d-11d6bad69483"
      },
      "source": [
        "packed_seqs = pack_padded_sequence(seqs, seq_lens, batch_first=True)\n",
        "packed_seqs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 6,  0,  4,  7,  1,  5,  8,  2,  9,  3, 10, 11])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPFmkzcKKC6E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ee5467ca-becd-472f-9ec3-193d78097c82"
      },
      "source": [
        "# Look at the batch size in seqs at each time step, this is equal to that\n",
        "packed_seqs[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 3, 2, 2, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHUAmyg_8lRT",
        "colab_type": "text"
      },
      "source": [
        "### Viterbi Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iwscu8yKMhv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ViterbiDecoder():\n",
        "  \"\"\"This is the decoder which considers the most likelihood tag sequence \n",
        "      considering the emission scores as well as the transition scores\"\"\"\n",
        "  def __init__(self, tag_map):\n",
        "    self.tagset_size = len(tag_map)\n",
        "    self.start_tag = tag_map['<start>']\n",
        "    self.end_tag = tag_map['<end>']\n",
        "\n",
        "  def decode(self, scores, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    word_pad_len = scores.size(1)\n",
        "\n",
        "    # Tensor to hold accumulated sequence scores at each tag\n",
        "    scores_upto_t = torch.zeros(batch_size, self.tagset_size)\n",
        "\n",
        "    # Tensor for backpointers\n",
        "    backpointers = torch.ones((batch_size, max(lengths), self.tagset_size), dtype=torch.long) * self.end_tag\n",
        "\n",
        "    for t in range(max(lengths)):\n",
        "      batch_size_t = sum([l > t for l in lengths]) # Batch size without pads\n",
        "      if t == 0:\n",
        "        scores_upto_t[:batch_size_t] = scores[:batch_size_t, t, self.start_tag, :]\n",
        "        backpointers[:batch_size_t, t,:] = torch.ones((batch_size_t, self.tagset_size), dtype=torch.long) * self.start_tag\n",
        "\n",
        "      else:\n",
        "        scores_upto_t[:batch_size_t], backpointers[:batch_size_t, t, :] = torch.max(scores[:batch_size_t, t, :, :] + scores_upto_t[:batch_size_t].unsqueeze(2), dim=1)\n",
        "\n",
        "    \n",
        "    decoded = torch.zeros((batch_size, backpointers.size(1)), dtype=torch.long)\n",
        "    pointer = torch.ones((batch_size, 1), dtype=torch.long) * self.end_tag\n",
        "\n",
        "    for t in list(reversed(range(backpointers.size(1)))):\n",
        "      decoded[:, t] = torch.gather(backpointers[:, t, :], 1, pointer).squeeze(1)\n",
        "      pointer = decoded[:, t].unsqueeze(1)\n",
        "\n",
        "    assert torch.equal(decoded[:, 0], torch.ones((batch_size), dtype=torch.long) * self.start_tag)\n",
        "\n",
        "    decoded = torch.cat([decoded[:, 1:], torch.ones((batch_size,1), dtype=torch.long)* self.start_tag], dim=1)\n",
        "\n",
        "    return decoded\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p02m2xiHR98",
        "colab_type": "text"
      },
      "source": [
        "### Model Creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iX9A3kTnBboz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svOogu9xHiJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Highway(nn.Module):\n",
        "  \"Highway Network\"\n",
        "\n",
        "  def __init__(self, size, num_layers=1, dropout=0.5):\n",
        "    super(Highway, self).__init__()\n",
        "    self.size = size\n",
        "    self.num_layers = num_layers\n",
        "    self.transform = nn.Modulelist()\n",
        "    self.gate = nn.Modulelist()\n",
        "    self.dropout = nn.Dropout(p = dropout)\n",
        "\n",
        "    for i in range(num_layers):\n",
        "      transform = nn.Linear(size, size)\n",
        "      gate = nn.Linear(size, size)\n",
        "      self.transform.append(transform)\n",
        "      self.gate.append(gate)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"Forward Propogation\"\n",
        "    transformed = nn.functional.relu(self.transform[0](x))\n",
        "    g = nn.functional.sigmoid(self.gate[0](x))\n",
        "\n",
        "    out = (g * transformed) + ((1-g) * x)\n",
        "\n",
        "    # For more than 1 layers\n",
        "    for i in range(1, self.num_layers):\n",
        "      out = self.dropout(out)\n",
        "      transformed = nn.functional.relu(self.transform[0](out))\n",
        "      g = nn.functional.sigmoid(self.gate[0](out))\n",
        "      out = (g * transformed) + ((1-g) * out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bA0WuXbXJWm4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CRF(nn.Module):\n",
        "  \"Conditional Random Field\"\n",
        "  def __init__(self, hidden_dim, tagset_size):\n",
        "    super(CRF, self).__init__()\n",
        "    self.tagset_size = tagset_size\n",
        "    self.emission = nn.Linear(hidden_dim, self.tagset_size)\n",
        "    self.transition = nn.Parameter(torch.Tensor(self.tagset_size, self.tagset_size))\n",
        "    self.transition.data.zero_()\n",
        "\n",
        "  def forward(self, feats):\n",
        "    self.batch_size = feats.size(0)\n",
        "    self.timesteps = feats.size(1)\n",
        "\n",
        "    emission_scores = self.emission(feats)\n",
        "    emission_scores = emission_scores.unsqueeze(2).expand(self.batch_size, self.timesteps, self.tagset_size, self.tagset_size)\n",
        "\n",
        "    crf_scores = emission_scores + self.transition.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    return crf_scores"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxPVLXRnLSLP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LM_LSTM_CRF(nn.Module):\n",
        "  \n",
        "  def __init__(self, tagset_size, charset_size, char_emb_dim, char_rnn_dim, char_rnn_layers,\n",
        "               vocab_size, lm_vocab_size, word_emb_dim, word_rnn_dim, word_rnn_layers, dropout,\n",
        "               highway_layers = 1):\n",
        "    super(LM_LSTM_CRF, self).__init__()\n",
        "    \n",
        "    self.tagset_size = tagset_size\n",
        "    self.charset_size = charset_size\n",
        "    self.char_emb_dim = char_emb_dim\n",
        "    self.char_rnn_dim = char_rnn_dim\n",
        "    self.char_rnn_layers = char_rnn_layers\n",
        "    self.wordset_size = vocab_size\n",
        "    self.lm_vocab_size = lm_vocab_size\n",
        "    self.word_emb_dim = word_emb_dim\n",
        "    self.word_rnn_dim = word_rnn_dim\n",
        "    self.word_rnn_layers = word_rnn_layers\n",
        "    self.highway_layers = highway_layers\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    # Character Embedding Layer\n",
        "    self.char_embeds = nn.Embedding(self.charset_size, self.char_emb_dim)\n",
        "    # Forward Character LSTM\n",
        "    self.forw_char_lstm = nn.LSTM(self.char_emb_dim, self.char_rnn_dim, num_layers=self.char_rnn_layers, bidirectional=False, dropout=dropout)\n",
        "    # Backward Character LSTM\n",
        "    self.back_char_lstm = nn.LSTM(self.char_emb_dim, self.char_rnn_dim, num_layers=self.char_rnn_layers, bidirectional=False, dropout=dropout)\n",
        "    # Word Embedding Layer\n",
        "    self.word_embeds = nn.Embedding(self.wordset_size, self.word_emb_dim)\n",
        "    # Word BLSTM\n",
        "    self.word_blstm = nn.LSTM(self.word_emb_dim + self.char_rnn_dim * 2, self.word_rnn_dim //2,\n",
        "                              num_layers = self.word_rnn_layers, bidirectional = True, dropout=dropout)\n",
        "    self.crf = CRF((self.word_rnn_dim // 2) * 2, self.tagset_size)\n",
        "    \n",
        "    # Highway for forward char LSTM output for language model\n",
        "    self.forw_lm_hw = Highway(self.char_rnn_dim, num_layers = self.highway_layers, dropout = dropout)\n",
        "    # Highway for backward char LSTM output for language model\n",
        "    self.back_lm_hw = Highway(self.char_rnn_dim, num_layers = self.highway_layers, dropout = dropout)\n",
        "\n",
        "    # Highway to combine and transform both forward and backward LSTM outputs for BLSTM\n",
        "    self.subword_hw = Highway(2 * self.char_rnn_dim, num_layers = self.highway_layers, dropout = dropout)\n",
        "\n",
        "    #Linear Model for vocab scores of forward language model\n",
        "    self.forw_lm_out = nn.Linear(self.char_rnn_dim, self.lm_vocab_size)\n",
        "    \n",
        "    #Linear Model for vocab scores of backward language model\n",
        "    self.back_lm_out = nn.Linear(self.char_rnn_dim, self.lm_vocab_size)\n",
        "\n",
        "  def init_word_embeddings(self, embeddings):\n",
        "    \"Initialize embeddings with pre-trained embeddings\"\n",
        "    self.word_embeds.weight = nn.Parameter(embeddings)\n",
        "\n",
        "  def fine_tune_word_embeddings(self, fine_tune=False):\n",
        "    \"Fine tune embedding layer if not using pre-trained embeddings\"\n",
        "    for p in self.word_embeds.parameter():\n",
        "      p.requires_grad = fine_tune\n",
        "\n",
        "  def forward(self, cmaps_f, cmaps_b, cmarkers_f, cmarkers_b, wmaps, tmaps, wmap_lengths, cmap_lengths):\n",
        "    \"Forward propogation\"\n",
        "    self.batch_size = cmaps_f.size(0)\n",
        "    self.word_pad_len = wmaps.size(1)\n",
        "\n",
        "    # Sort by decreasing true char length\n",
        "    cmap_lengths, char_sort_ind = cmap_lengths.sort(dim=0, descending=True)\n",
        "    cmaps_f = cmaps_f[char_sort_ind]\n",
        "    cmaps_b = cmaps_b[char_sort_ind]\n",
        "    cmarkers_f = cmarkers_f[char_sort_ind]\n",
        "    cmarkers_b = cmarkers_b[char_sort_ind]\n",
        "    wmaps = wmaps[char_sort_ind]\n",
        "    tmaps = tmaps[char_sort_ind]\n",
        "    wmap_lengths = wmap_lengths[char_sort_ind]\n",
        "\n",
        "    # Embedding look-up for characters\n",
        "    cf = self.char_embeds(cmaps_f)\n",
        "    cb = self.char_embeds(cmaps_b)\n",
        "\n",
        "    # Dropout\n",
        "    cf = self.dropout(cf)\n",
        "    cb = self.dropout(cb)\n",
        "\n",
        "    # Pack padded sequence\n",
        "    cf = pack_padded_sequence(cf, cmap_lengths.tolist(), batch_first=True)\n",
        "    cb = pack_padded_sequence(cb, cmap_lengths.tolist(), batch_first=True)\n",
        "\n",
        "    # LSTM \n",
        "    cf, _ = self.forw_char_lstm(cf)\n",
        "    cb, _ = self.back_char_lstm(cb)\n",
        "\n",
        "    # Unpack packed sequence\n",
        "    cf, _ = pad_packed_sequence(cf, batch_first=True)\n",
        "    cb, _ = pad_packed_sequence(cb, batch_first=True)\n",
        "\n",
        "    # Sanity check\n",
        "    assert cf.size(1) == max(cmap_lengths.tolist()) == list(cmap_lengths)[0]\n",
        "\n",
        "    # Select RNN outputs only at marker points\n",
        "    cmarkers_f = cmarkers_f.unsqueeze(2).expand(self.batch_size, self.word_pad_len, self.char_rnn_dim)\n",
        "    cmarkers_b = cmarkers_b.unsqueeze(2).expand(self.batch_size, self.word_pad_len, self.char_rnn_dim)\n",
        "    cf_selected = torch.gather(cf, 1, cmarkers_f)\n",
        "    cb_selected = torch.gather(cb, 1, cmarkers_b)\n",
        "\n",
        "    # Only for co-training, not useful in tagging\n",
        "    if self.training:\n",
        "      lm_f = self.forw_lm_hw(self.dropout(cf_selected))\n",
        "      lm_b = self.back_lm_hw(self.dropout(cb_selected))\n",
        "      lm_f_scores = self.forw_lm_out(self.dropout(lm_f))\n",
        "      lm_b_scores = self.back_lm_out(self.dropout(lm_b))\n",
        "\n",
        "    # Sort by decreasing true word lengths\n",
        "    wmap_lengths, word_sort_ind = wmap_lengths.sort(dim=0, descending=True)\n",
        "    wmaps = wmaps[word_sort_ind]\n",
        "    tmaps = tmaps[word_sort_ind]\n",
        "    cf_selected = cf_selected[word_sort_ind]\n",
        "    cb_selected = cb_selected[word_sort_ind]\n",
        "    if self.training:\n",
        "      lm_f_scores = lm_f_scores[word_sort_ind]\n",
        "      lm_b_scores = lm_b_scores[word_sort_ind]\n",
        "\n",
        "    # Embedding word lookups\n",
        "    w = self.word_embeds(wmaps)\n",
        "    w = self.dropout(w)\n",
        "\n",
        "    # Subword information of each word\n",
        "    subword = self.subword_hw(self.dropout(torch.cat((cf_selected, cb_selected),dim=2)))\n",
        "    subword = self.dropout(subword)\n",
        "\n",
        "    # Concatenate Word embeddings and subword features\n",
        "    w = torch.cat((w, subword), dim=2)\n",
        "\n",
        "    # Pack padded sequence\n",
        "    w = pack_padded_sequence(w, list(wmap_lengths), batch_first=True)\n",
        "\n",
        "    # LSTM\n",
        "    w, _ = self.word_blstm(w)\n",
        "\n",
        "    # Unpack\n",
        "    w, _ = pad_packed_sequence(w, batch_first=True)\n",
        "    w = self.dropout(w)\n",
        "\n",
        "    crf_scores = self.crf(w)\n",
        "\n",
        "    if self.training:\n",
        "      return crf_scores, lm_f_scores, lm_b_scores, wmaps, tmaps, wmap_lengths, word_sort_ind, char_sort_ind\n",
        "    \n",
        "    else:\n",
        "      return crf_scores, wmaps, tmaps, wmap_lengths, word_sort_ind, char_sort_ind\n",
        "   "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJhxroRDaJxP",
        "colab_type": "text"
      },
      "source": [
        "## Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2B7qNRjzaFhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ViterbiLoss(nn.Module):\n",
        "  \"Viterbi Loss\"\n",
        "  def __init__(self, tag_map):\n",
        "    super(ViterbiLoss, self).__init__()\n",
        "    self.tagset_size = len(tag_map)\n",
        "    self.start_tag = tag_map['<start>']\n",
        "    self.end_tag = tag_map['<end>']\n",
        "\n",
        "  def forward(self, scores, targets, lengths):\n",
        "    batch_size = scores.size(0)\n",
        "    word_pad_len = scores.size(1)\n",
        "\n",
        "    # Gold score\n",
        "    targets = targets.unsqueeze(2)\n",
        "    scores_at_targets = torch.gather(scores.view(batch_size, word_pad_len, -1), 2, targets).squeeze(2)\n",
        "\n",
        "    scores_at_targets, _ = pack_padded_sequence(scores_at_targets, lengths, batch_first=True)\n",
        "    gold_score = scores_at_targets.sum()\n",
        "\n",
        "    # All path scores\n",
        "    scores_upto_t = torch.zeros(batch_size, self.tagset_size).to(device)\n",
        "\n",
        "    for t in range(max(lengths)):\n",
        "      batch_size_t = sum([l > t for l in lengths])\n",
        "      if t == 0:\n",
        "        scores_upto_t[:batch_size_t] = scores[:batch_size_t, t, self.start_tag, :]\n",
        "      else:\n",
        "        scores_upto_t[:batch_size_t] = log_sum_exp(scores[:batch_size_t, t, :, :] + scores_upto_t[:batch_size_t].unsqueeze(2),dim=1)\n",
        "\n",
        "    all_path_scores = scores_upto_t[:, self.end_tag].sum()\n",
        "\n",
        "    viterbi_loss = all_path_scores - gold_score\n",
        "    viterbi_loss /= batch_size\n",
        "\n",
        "    return viterbi_loss"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2SkBxrHdBS4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}